# ai_reports/ai_analyzer.py
"""
ü§ñ AI Analyzer - Integra√ß√£o com Ollama/Qwen 2.5
Processa dados coletados e gera insights inteligentes para relat√≥rios
"""

import json
import requests
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from config import Config

# Configurar logging
logger = logging.getLogger(__name__)


class AIAnalyzer:
    """
    ü§ñ Analisador IA para dados de atendimento
    
    Conecta com Ollama (Qwen 2.5:3b) para gerar insights autom√°ticos
    sobre performance de supervisores e agentes
    """
    
    def __init__(self):
        """Inicializa o analisador IA"""
        self.ollama_url = Config.OLLAMA_BASE_URL
        self.model = Config.OLLAMA_MODEL
        self.timeout = Config.OLLAMA_TIMEOUT
        self.debug = Config.AI_REPORTS_DEBUG
        
        if self.debug:
            logger.info(f"ü§ñ AIAnalyzer inicializado - {self.model} @ {self.ollama_url}")
    
    def test_connection(self) -> Dict[str, Any]:
        """
        üîå Testa conex√£o com Ollama
        
        Returns:
            Dict com resultado do teste
        """
        try:
            # Testar endpoint de health check
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=10)
            
            if response.status_code == 200:
                models_data = response.json()
                available_models = [model['name'] for model in models_data.get('models', [])]
                
                model_available = any(self.model in model for model in available_models)
                
                result = {
                    'success': True,
                    'status': 'Connected',
                    'ollama_url': self.ollama_url,
                    'available_models': available_models,
                    'target_model': self.model,
                    'model_available': model_available,
                    'timestamp': datetime.now().isoformat()
                }
                
                if model_available:
                    logger.info(f"‚úÖ Ollama conectado - Modelo {self.model} dispon√≠vel")
                else:
                    logger.warning(f"‚ö†Ô∏è Ollama conectado - Modelo {self.model} N√ÉO dispon√≠vel")
                
                return result
            else:
                raise Exception(f"HTTP {response.status_code}")
                
        except Exception as e:
            error_msg = f"Erro na conex√£o com Ollama: {e}"
            logger.error(f"‚ùå {error_msg}")
            
            return {
                'success': False,
                'error': error_msg,
                'ollama_url': self.ollama_url,
                'timestamp': datetime.now().isoformat()
            }
    
    def analyze_weekly_data(self, weekly_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        üìä Analisa dados semanais completos com IA
        
        Args:
            weekly_data: Dados coletados pelo DataCollector
            
        Returns:
            Dict com an√°lise completa da IA
        """
        try:
            if self.debug:
                logger.info("üß† Iniciando an√°lise IA dos dados semanais...")
            
            # Gerar an√°lise global
            global_analysis = self._analyze_global_trends(weekly_data)
            
            # Gerar an√°lise por supervisor
            supervisors_analysis = []
            for supervisor_data in weekly_data['supervisors_data']:
                analysis = self._analyze_supervisor_performance(supervisor_data, weekly_data)
                supervisors_analysis.append(analysis)
            
            # Gerar recomenda√ß√µes estrat√©gicas
            strategic_recommendations = self._generate_strategic_recommendations(weekly_data)
            
            # Compilar an√°lise final
            ai_analysis = {
                'metadata': {
                    'generated_at': datetime.now().isoformat(),
                    'ai_model': self.model,
                    'analysis_period': weekly_data['metadata']['current_week']['period_label']
                },
                'global_analysis': global_analysis,
                'supervisors_analysis': supervisors_analysis,
                'strategic_recommendations': strategic_recommendations,
                'summary': self._generate_executive_summary(weekly_data, global_analysis, supervisors_analysis)
            }
            
            if self.debug:
                logger.info(f"‚úÖ An√°lise IA conclu√≠da - {len(supervisors_analysis)} supervisores analisados")
            
            return ai_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise IA: {e}")
            raise
    
    def _analyze_global_trends(self, weekly_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        üåç Analisa tend√™ncias globais do sistema
        """
        global_stats = weekly_data['global_stats']
        
        # Preparar dados para IA
        analysis_prompt = self._build_global_analysis_prompt(global_stats, weekly_data)
        
        # Solicitar an√°lise da IA
        ai_response = self._query_ollama(analysis_prompt, "global_trends")
        
        return {
            'trend_analysis': ai_response,
            'key_metrics': {
                'total_tickets': global_stats['current_week']['total_tickets'],
                'change_percent': global_stats['comparison']['percent_change'],
                'trend_direction': global_stats['comparison']['trend'],
                'active_supervisors': global_stats['current_week']['active_supervisors']
            },
            'insights': self._extract_insights_from_ai_response(ai_response)
        }
    
    def _analyze_supervisor_performance(self, supervisor_data: Dict[str, Any], 
                                       weekly_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        üë§ Analisa performance individual de um supervisor
        """
        supervisor_name = supervisor_data['supervisor']['name']
        
        # Preparar dados para IA
        analysis_prompt = self._build_supervisor_analysis_prompt(supervisor_data, weekly_data)
        
        # Solicitar an√°lise da IA
        ai_response = self._query_ollama(analysis_prompt, f"supervisor_{supervisor_name}")
        
        return {
            'supervisor_id': supervisor_data['supervisor']['id'],
            'supervisor_name': supervisor_name,
            'performance_analysis': ai_response,
            'key_metrics': {
                'current_tickets': supervisor_data['current_week']['total_tickets'],
                'change_percent': supervisor_data['comparison']['percent_change'],
                'agents_count': len(supervisor_data['current_week']['agents_performance']),
                'trend': supervisor_data['comparison']['trend']
            },
            'agents_insights': self._analyze_agents_performance(supervisor_data['current_week']['agents_performance']),
            'recommendations': self._extract_recommendations_from_ai_response(ai_response)
        }
    
    def _analyze_agents_performance(self, agents_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        üë• Analisa performance dos agentes
        """
        agents_insights = []
        
        for agent in agents_data:
            agent_name = agent['agent']['name']
            current_tickets = agent['current_tickets']
            change = agent['change']
            
            # Classificar performance
            if change > 0:
                if change >= 10:
                    performance_level = "Alta demanda"
                    status = "warning"
                else:
                    performance_level = "Crescimento est√°vel"
                    status = "success"
            elif change < 0:
                performance_level = "Redu√ß√£o"
                status = "info"
            else:
                performance_level = "Est√°vel"
                status = "neutral"
            
            # Detectar padr√µes at√≠picos
            change_percent = ((change / agent['previous_tickets']) * 100) if agent['previous_tickets'] > 0 else 0
            is_atypical = abs(change_percent) >= 50
            
            agents_insights.append({
                'agent_name': agent_name,
                'current_tickets': current_tickets,
                'change': change,
                'change_percent': round(change_percent, 1),
                'performance_level': performance_level,
                'status': status,
                'is_atypical': is_atypical,
                'needs_attention': is_atypical or current_tickets >= 50  # Mais de 50 tickets pode indicar sobrecarga
            })
        
        return agents_insights
    
    def _generate_strategic_recommendations(self, weekly_data: Dict[str, Any]) -> List[str]:
        """
        üéØ Gera recomenda√ß√µes estrat√©gicas baseadas nos dados
        """
        # Preparar dados para IA
        strategy_prompt = self._build_strategy_prompt(weekly_data)
        
        # Solicitar recomenda√ß√µes da IA
        ai_response = self._query_ollama(strategy_prompt, "strategic_recommendations")
        
        # Extrair recomenda√ß√µes espec√≠ficas
        recommendations = self._extract_recommendations_from_ai_response(ai_response)
        
        return recommendations
    
    def _generate_executive_summary(self, weekly_data: Dict[str, Any], 
                                   global_analysis: Dict[str, Any],
                                   supervisors_analysis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        üìã Gera resumo executivo para coordena√ß√£o usando prompt especializado
        """
        try:
            from .ai_prompts import PromptBuilder
            
            # Gerar prompt para resumo executivo
            executive_prompt = PromptBuilder.executive_summary(weekly_data, global_analysis, supervisors_analysis)
            
            # Solicitar an√°lise da IA
            ai_summary = self._query_ollama(executive_prompt, "executive_summary")
        except ImportError:
            # Fallback se ai_prompts n√£o estiver dispon√≠vel
            ai_summary = "Resumo executivo indispon√≠vel"
        
        total_tickets = weekly_data['global_stats']['current_week']['total_tickets']
        total_change = weekly_data['global_stats']['comparison']['absolute_change']
        
        # Top performer
        top_supervisor = max(supervisors_analysis, key=lambda x: x['key_metrics']['current_tickets']) if supervisors_analysis else None
        
        # Supervisores que precisam de aten√ß√£o
        attention_needed = [
            s for s in supervisors_analysis 
            if abs(s['key_metrics']['change_percent']) >= 30 or any(agent.get('needs_attention', False) for agent in s.get('agents_insights', []))
        ]
        
        return {
            'total_tickets': total_tickets,
            'weekly_change': total_change,
            'change_percent': weekly_data['global_stats']['comparison']['percent_change'],
            'top_supervisor': {
                'name': top_supervisor['supervisor_name'] if top_supervisor else 'N/A',
                'tickets': top_supervisor['key_metrics']['current_tickets'] if top_supervisor else 0
            },
            'supervisors_needing_attention': len(attention_needed),
            'overall_trend': weekly_data['global_stats']['comparison']['trend'],
            'ai_generated_summary': ai_summary,
            'key_insights': global_analysis.get('insights', [])[:3],  # Top 3 insights
            'priority_actions': len([s for s in supervisors_analysis if s['key_metrics']['change_percent'] >= 50])
        }
    
    def _build_global_analysis_prompt(self, global_stats: Dict[str, Any], weekly_data: Dict[str, Any]) -> str:
        """
        üî§ Constr√≥i prompt para an√°lise global usando prompts especializados
        """
        try:
            from .ai_prompts import PromptBuilder
            from .ai_refinements import PromptOptimizer
            
            # Gerar prompt base
            base_prompt = PromptBuilder.global_trend_analysis(global_stats, weekly_data)
            
            # Aplicar otimiza√ß√µes
            context = {
                'change_percent': global_stats['comparison']['percent_change'],
                'total_tickets': global_stats['current_week']['total_tickets']
            }
            
            optimized_prompt = PromptOptimizer.enhance_global_prompt(base_prompt, context)
            return optimized_prompt
        except ImportError:
            # Fallback b√°sico se m√≥dulos n√£o estiverem dispon√≠veis
            current_tickets = global_stats['current_week']['total_tickets']
            previous_tickets = global_stats['previous_week']['total_tickets']
            change = global_stats['comparison']['absolute_change']
            change_percent = global_stats['comparison']['percent_change']
            
            period = weekly_data['metadata']['current_week']['period_label']
            
            prompt = f"""
Analise os dados semanais de atendimento e forne√ßa insights profissionais:

PER√çODO: {period}
ATENDIMENTOS ATUAIS: {current_tickets}
ATENDIMENTOS ANTERIORES: {previous_tickets}
VARIA√á√ÉO: {change:+d} ({change_percent:+.1f}%)

Forne√ßa uma an√°lise concisa focando em:
1. Interpreta√ß√£o da tend√™ncia geral
2. Poss√≠veis causas da varia√ß√£o
3. Impacto operacional
4. A√ß√µes recomendadas

Seja objetivo e professional. M√°ximo 200 palavras.
"""
            return prompt.strip()
    
    def _build_supervisor_analysis_prompt(self, supervisor_data: Dict[str, Any], weekly_data: Dict[str, Any]) -> str:
        """
        üî§ Constr√≥i prompt para an√°lise de supervisor usando prompts especializados
        """
        try:
            from .ai_prompts import PromptBuilder
            from .ai_refinements import PromptOptimizer
            
            # Calcular ranking do supervisor
            all_supervisors = weekly_data.get('supervisors_data', [])
            ranking = None
            
            if all_supervisors:
                sorted_supervisors = sorted(all_supervisors, key=lambda x: x['current_week']['total_tickets'], reverse=True)
                for i, sup in enumerate(sorted_supervisors, 1):
                    if sup['supervisor']['id'] == supervisor_data['supervisor']['id']:
                        ranking = i
                        break
            
            # Gerar prompt base
            base_prompt = PromptBuilder.supervisor_performance_analysis(supervisor_data, weekly_data, ranking)
            
            # Aplicar otimiza√ß√µes
            optimized_prompt = PromptOptimizer.enhance_supervisor_prompt(base_prompt, supervisor_data)
            return optimized_prompt
        except ImportError:
            # Fallback b√°sico se m√≥dulos n√£o estiverem dispon√≠veis
            supervisor_name = supervisor_data['supervisor']['name']
            current = supervisor_data['current_week']['total_tickets']
            previous = supervisor_data['previous_week']['total_tickets']
            change = supervisor_data['comparison']['absolute_change']
            change_percent = supervisor_data['comparison']['percent_change']
            
            agents = supervisor_data['current_week']['agents_performance']
            agents_summary = []
            for agent in agents[:3]:  # Top 3 agentes
                agents_summary.append(f"{agent['agent']['name']}: {agent['current_tickets']} atendimentos ({agent['change']:+d})")
            
            period = weekly_data['metadata']['current_week']['period_label']
            
            prompt = f"""
Analise a performance do supervisor {supervisor_name} no per√≠odo {period}:

SUPERVISOR: {supervisor_name}
ATENDIMENTOS: {current} (anterior: {previous})
VARIA√á√ÉO: {change:+d} ({change_percent:+.1f}%)

PRINCIPAIS AGENTES:
{chr(10).join(agents_summary)}

Forne√ßa an√°lise focada em:
1. Avalia√ß√£o da performance
2. An√°lise da distribui√ß√£o entre agentes
3. Identifica√ß√£o de padr√µes
4. Recomenda√ß√µes espec√≠ficas

Seja conciso e actionable. M√°ximo 150 palavras.
"""
            return prompt.strip()
    
    def _build_strategy_prompt(self, weekly_data: Dict[str, Any]) -> str:
        """
        üî§ Constr√≥i prompt para recomenda√ß√µes estrat√©gicas usando prompts especializados
        """
        try:
            from .ai_prompts import PromptBuilder
            from .ai_refinements import PromptOptimizer
            
            # Gerar prompt base
            base_prompt = PromptBuilder.strategic_recommendations(weekly_data)
            
            # Aplicar otimiza√ß√µes
            strategic_context = {
                'supervisors_data': weekly_data['supervisors_data'],
                'global_stats': weekly_data['global_stats']
            }
            
            optimized_prompt = PromptOptimizer.enhance_strategic_prompt(base_prompt, strategic_context)
            return optimized_prompt
        except ImportError:
            # Fallback b√°sico se m√≥dulos n√£o estiverem dispon√≠veis
            supervisors = weekly_data['supervisors_data']
            global_stats = weekly_data['global_stats']
            
            # Resumo dos supervisores
            supervisors_summary = []
            for sup in supervisors[:5]:  # Top 5
                name = sup['supervisor']['name']
                tickets = sup['current_week']['total_tickets']
                change = sup['comparison']['absolute_change']
                supervisors_summary.append(f"{name}: {tickets} atendimentos ({change:+d})")
            
            prompt = f"""
Com base nos dados semanais, forne√ßa 3-5 recomenda√ß√µes estrat√©gicas para a gest√£o:

CEN√ÅRIO GERAL:
- Total: {global_stats['current_week']['total_tickets']} atendimentos
- Varia√ß√£o: {global_stats['comparison']['absolute_change']:+d} ({global_stats['comparison']['percent_change']:+.1f}%)

SUPERVISORES:
{chr(10).join(supervisors_summary)}

Foque em:
1. Redistribui√ß√£o de carga
2. Apoio a supervisores
3. Otimiza√ß√£o de processos
4. Preven√ß√£o de problemas

Seja espec√≠fico e pr√°tico. Uma recomenda√ß√£o por linha.
"""
            return prompt.strip()
    
    def _query_ollama(self, prompt: str, context: str = "") -> str:
        """
        ü§ñ Faz consulta ao Ollama com melhorias na resposta
        
        Args:
            prompt: Prompt para a IA
            context: Contexto da consulta (para logs)
            
        Returns:
            Resposta da IA melhorada
        """
        try:
            if self.debug:
                logger.info(f"ü§ñ Consultando Ollama - {context}")
            
            # Adicionar system prompt restritivo
            payload = {
                "model": self.model,
                "prompt": prompt,
                "system": "Voc√™ √© um analista de contabilidade. NUNCA mencione f√©rias escolares, sazonalidade ou educa√ß√£o. Foque APENAS em empresa de contabilidade interna. Use APENAS os dados fornecidos.",
                "stream": False,
                "options": {
                    "temperature": 0.05,  # Ainda mais baixo
                    "top_p": 0.7,
                    "max_tokens": 150,    # Ainda menor
                    "repeat_penalty": 1.3
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                raw_response = result.get('response', '').strip()
                
                # Aplicar melhorias na resposta
                try:
                    from .ai_refinements import ResponseEnhancer
                    enhanced = ResponseEnhancer.enhance_ai_response(raw_response, context)
                    
                    # Log qualidade da resposta se em debug
                    if self.debug:
                        quality = enhanced['quality_score']
                        confidence = enhanced['confidence_metrics']
                        logger.info(f"‚úÖ IA resposta - Qualidade: {quality['level']} ({quality['score']}/4), Confian√ßa: {confidence['confidence_level']}")
                    
                    # Retornar resposta limpa
                    final_response = enhanced['cleaned_response']
                    
                    # Se resposta for muito curta, usar resposta original
                    if len(final_response) < 50 and len(raw_response) > len(final_response):
                        final_response = raw_response
                    
                    return final_response
                except ImportError:
                    # Fallback se m√≥dulo de refinements n√£o estiver dispon√≠vel
                    return raw_response
            else:
                raise Exception(f"HTTP {response.status_code}: {response.text}")
                
        except Exception as e:
            error_msg = f"Erro na consulta Ollama ({context}): {e}"
            logger.error(f"‚ùå {error_msg}")
            
            # Fallback melhorado
            try:
                from .ai_refinements import ResponseEnhancer
                fallback = ResponseEnhancer._create_fallback_response(context)
                return fallback['cleaned_response']
            except ImportError:
                return f"[Erro na an√°lise IA: {e}]"
    
    def _extract_insights_from_ai_response(self, ai_response: str) -> List[str]:
        """
        üìù Extrai insights principais da resposta da IA
        """
        if not ai_response or ai_response.startswith("[Erro"):
            return ["An√°lise indispon√≠vel"]
        
        # Dividir em senten√ßas e filtrar insights relevantes
        sentences = [s.strip() for s in ai_response.split('.') if s.strip()]
        insights = []
        
        for sentence in sentences[:4]:  # M√°ximo 4 insights
            if len(sentence) > 20 and not sentence.startswith("["):
                insights.append(sentence + ".")
        
        return insights if insights else ["Nenhum insight espec√≠fico identificado"]
    
    def _extract_recommendations_from_ai_response(self, ai_response: str) -> List[str]:
        """
        üìã Extrai recomenda√ß√µes da resposta da IA
        """
        if not ai_response or ai_response.startswith("[Erro"):
            return ["An√°lise indispon√≠vel"]
        
        # Procurar por listas numeradas ou com bullets
        lines = ai_response.split('\n')
        recommendations = []
        
        for line in lines:
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith('-') or line.startswith('‚Ä¢')):
                # Limpar numera√ß√£o/bullets
                clean_line = line.lstrip('0123456789.-‚Ä¢ ').strip()
                if len(clean_line) > 10:
                    recommendations.append(clean_line)
        
        # Se n√£o encontrou listas, usar senten√ßas
        if not recommendations:
            sentences = [s.strip() for s in ai_response.split('.') if s.strip()]
            recommendations = [s + "." for s in sentences[:3] if len(s) > 20]
        
        return recommendations if recommendations else ["Nenhuma recomenda√ß√£o espec√≠fica"]


# Fun√ß√£o de conveni√™ncia para uso externo
def analyze_weekly_data(weekly_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    üîß Fun√ß√£o utilit√°ria para an√°lise de dados semanais
    
    Args:
        weekly_data: Dados coletados pelo DataCollector
        
    Returns:
        An√°lise completa da IA
    """
    analyzer = AIAnalyzer()
    return analyzer.analyze_weekly_data(weekly_data)


def test_ai_connection() -> Dict[str, Any]:
    """
    üß™ Fun√ß√£o utilit√°ria para testar conex√£o com IA
    
    Returns:
        Resultado do teste de conex√£o
    """
    analyzer = AIAnalyzer()
    return analyzer.test_connection()